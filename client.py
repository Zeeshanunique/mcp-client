# Import necessary libraries
import asyncio  # For handling asynchronous operations
import os       # For environment variable access
import sys      # For system-specific parameters and functions
import json     # For handling JSON data (used when printing function declarations)

# Import MCP client components
from typing import Optional, Any, Dict, List  # For type hinting optional values
from contextlib import AsyncExitStack  # For managing multiple async tasks
from mcp import ClientSession, StdioServerParameters  # MCP session management
from mcp.client.stdio import stdio_client  # MCP client for standard I/O communication

# Import Google's Gen AI SDK
from google import genai
from google.genai import types
from google.genai.types import Tool, FunctionDeclaration
from google.genai.types import GenerateContentConfig

from dotenv import load_dotenv  # For loading API keys from a .env file

# Load environment variables from .env file
load_dotenv()

class MCPClient:
    def __init__(self):
        """Initialize the MCP client and configure the Gemini API."""
        self.session: Optional[ClientSession] = None  # MCP session for communication
        self.exit_stack = AsyncExitStack()  # Manages async resource cleanup
        self.conversation_history = []  # Store conversation history

        # Retrieve the Gemini API key from environment variables
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        if not gemini_api_key:
            raise ValueError("GEMINI_API_KEY not found. Please add it to your .env file.")

        # Configure the Gemini AI client
        self.genai_client = genai.Client(api_key=gemini_api_key)

    async def connect_to_server(self, server_script_path: str):
        """Connect to the MCP server and list available tools."""

        # Determine whether the server script is written in Python or JavaScript
        # This allows us to execute the correct command to start the MCP server
        command = "python" if server_script_path.endswith('.py') else "node"

        # Define the parameters for connecting to the MCP server
        server_params = StdioServerParameters(command=command, args=[server_script_path])

        # Establish communication with the MCP server using standard input/output (stdio)
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))

        # Extract the read/write streams from the transport object
        self.stdio, self.write = stdio_transport

        # Initialize the MCP client session, which allows interaction with the server
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))

        # Send an initialization request to the MCP server
        await self.session.initialize()

        # Request the list of available tools from the MCP server
        response = await self.session.list_tools()
        tools = response.tools  # Extract the tool list from the response

        # Check if websearch is present among tools
        has_websearch = any(tool.name == "websearch" for tool in tools)
        
        # Print a message showing the names of the tools available on the server
        print("\nConnected to server with tools:", [tool.name for tool in tools])
        
        # Check SerpAPI configuration if websearch is available
        if has_websearch:
            serpapi_key = os.getenv("SERPAPI_KEY")
            if not serpapi_key:
                print("\n[WARNING] SERPAPI_KEY environment variable not set.")
                print("Web search functionality will not work correctly.")
                print("Please add your SerpAPI key to your .env file: SERPAPI_KEY=your_key_here")
            else:
                print(f"\n[OK] SERPAPI_KEY is configured (length: {len(serpapi_key)})")

        # Convert MCP tools to Gemini format
        self.function_declarations = convert_mcp_tools_to_gemini(tools)


    async def process_query(self, query: str) -> str:
        """
        Process a user query using the Gemini API and execute tool calls if needed.
        

        Args:
            query (str): The user's input query.

        Returns:
            str: The response generated by the Gemini model.
        """

        # Format user input as a structured Content object for Gemini
        user_prompt_content = types.Content(
            role='user',  # Indicates that this is a user message
            parts=[types.Part.from_text(text=query)]  # Convert the text query into a Gemini-compatible format
        )

        # Add user query to conversation history
        self.conversation_history.append(user_prompt_content)
        
        # Use the full conversation history for context
        contents_history = self.conversation_history.copy()

        # Send user input to Gemini AI and include available tools for function calling
        response = self.genai_client.models.generate_content(
            model='gemini-2.0-flash-lite',  # Specifies which Gemini model to use
            contents=contents_history,  # Send full conversation history to Gemini
            config=types.GenerateContentConfig(
                tools=self.function_declarations,  # Pass the list of available MCP tools for Gemini to use
            ),
        )

        # Continue processing until no more function calls are requested
        max_iterations = 5  # Safety limit to prevent infinite loops
        iteration = 0

        while iteration < max_iterations:
            iteration += 1
            
            # Check if response contains any function calls
            has_function_calls = False
            
            for candidate in response.candidates:
                for part in candidate.content.parts:
                    if isinstance(part, types.Part) and part.function_call:
                        has_function_calls = True
                        break
                if has_function_calls:
                    break
            
            # If no function calls, break the loop
            if not has_function_calls:
                break
                
            # Process function calls and add to history
            for candidate in response.candidates:
                # Add assistant's response to history
                assistant_content = types.Content(
                    role='assistant',
                    parts=candidate.content.parts
                )
                contents_history.append(assistant_content)
                self.conversation_history.append(assistant_content)
                
                # Process each function call
                for part in candidate.content.parts:
                    if isinstance(part, types.Part) and part.function_call:
                        # Extract function call details
                        tool_name = part.function_call.name
                        tool_args = part.function_call.args
                        
                        # Print debug info
                        print(f"\n[Gemini requested tool call: {tool_name} with args {tool_args}]")
                        
                        # Ensure the steps parameter is a JSON string
                        if tool_name == "orchestrate" and "steps" in tool_args:
                            tool_args["steps_json"] = json.dumps(tool_args.pop("steps"))
                            
                        # Execute the tool using the MCP server
                        try:
                            result = await self.session.call_tool(tool_name, tool_args)
                            
                            # Check for errors
                            if isinstance(result.content, Dict) and "error" in result.content:
                                print(f"\n[Tool error: {result.content['error']}]")
                                
                                # Extract any solution if available
                                solution = result.content.get("solution", "")
                                suggestion = result.content.get("suggestion", "")
                                
                                error_with_help = {
                                    "error": result.content["error"],
                                    "status": "error"
                                }
                                
                                # Add any solutions or suggestions if available
                                if solution:
                                    error_with_help["solution"] = solution
                                    print(f"[Solution: {solution}]")
                                if suggestion:
                                    error_with_help["suggestion"] = suggestion
                                    print(f"[Suggestion: {suggestion}]")
                                    
                                function_response = {"result": error_with_help}
                                
                                # Special case for websearch with no results
                                if tool_name == "websearch" and "No results found" in str(result.content):
                                    return "I'm sorry, I couldn't find any web search results for that query. " + \
                                           (solution or "") + " " + (suggestion or "") + \
                                           "\n\nPlease check that your SERPAPI_KEY is valid in your .env file."
                                    
                                # Special case for websearch API key issues
                                if tool_name == "websearch" and "SERPAPI_KEY" in str(result.content):
                                    return "Web search functionality is not properly configured. " + \
                                           "Please add your SerpAPI key to your .env file: SERPAPI_KEY=your_key_here\n\n" + \
                                           "You can get a free SerpAPI key by signing up at https://serpapi.com/"
                                    
                                # Special case for authentication errors
                                if tool_name == "websearch" and ("authentication" in str(result.content).lower() or "invalid key" in str(result.content).lower()):
                                    return "Your SerpAPI key appears to be invalid or has expired. " + \
                                           "Please check your SERPAPI_KEY in the .env file and make sure it's valid.\n\n" + \
                                           "You can verify your key at https://serpapi.com/dashboard"
                            else:
                                # Special handling for websearch successful results
                                if tool_name == "websearch" and isinstance(result.content, Dict) and "results" in result.content:
                                    # Print debug info about search results
                                    count = result.content.get("count", 0)
                                    print(f"\n[Retrieved {count} search results]")
                                    
                                function_response = {"result": result.content, "status": "success"}
                        except Exception as e:
                            error_msg = str(e)
                            print(f"\n[Error executing tool: {error_msg}]")
                            function_response = {"result": {"error": error_msg, "status": "error"}}
                            
                            # Handle common connection errors
                            if "connection" in error_msg.lower():
                                return "I'm having trouble connecting to external services. Please check your internet connection and try again."
                        
                        # Format the tool response for Gemini
                        function_response_content = types.Content(
                            role='tool',
                            parts=[
                                types.Part.from_function_response(
                                    name=tool_name,
                                    response=function_response
                                )
                            ]
                        )
                        
                        # Add tool response to history
                        contents_history.append(function_response_content)
                        self.conversation_history.append(function_response_content)
            
            # Get next response from Gemini with updated history
            try:
                response = self.genai_client.models.generate_content(
                    model='gemini-2.0-flash-001',
                    contents=contents_history,
                    config=types.GenerateContentConfig(
                        tools=self.function_declarations,
                    ),
                )
            except Exception as e:
                print(f"\n[Error in Gemini processing: {str(e)}]")
                if "empty" in str(e).lower() or "no results" in str(e).lower():
                    return "I couldn't find any information about that. Please try a different query or check your API setup."
                return f"I encountered an issue processing the results: {str(e)}"
        
        # Extract final response
        if not response.candidates or not response.candidates[0].content.parts:
            return "I couldn't generate a response. Please check your API keys and try again."
        
        # Get the final text response
        final_response = ""
        for part in response.candidates[0].content.parts:
            if isinstance(part, types.Part) and not part.function_call:
                final_response += part.text
        
        # Add the assistant's response to the conversation history
        assistant_content = types.Content(
            role='assistant',
            parts=[types.Part.from_text(text=final_response)]
        )
        self.conversation_history.append(assistant_content)

        return final_response


    async def chat_loop(self):
        """Run an interactive chat session with the user."""
        print("\nMCP Client Started! Type 'quit' to exit.")
        print("Special commands: 'clear' - Clear conversation history, 'history' - Show conversation history")

        while True:
            query = input("\nQuery: ").strip()
            if query.lower() == 'quit':
                break
            elif query.lower() == 'clear':
                self.conversation_history = []
                print("Conversation history cleared.")
                continue
            elif query.lower() == 'history':
                if not self.conversation_history:
                    print("No conversation history yet.")
                else:
                    print("\n----- Conversation History -----")
                    for i, content in enumerate(self.conversation_history):
                        role = content.role
                        if hasattr(content, 'parts') and content.parts:
                            text = content.parts[0].text if hasattr(content.parts[0], 'text') else "[Function call]"
                            print(f"{role.upper()}: {text[:100]}{'...' if len(text) > 100 else ''}")
                    print("---------------------------------")
                continue

            # Process the user's query and display the response
            response = await self.process_query(query)
            print("\n" + response)

    async def cleanup(self):
        """Clean up resources before exiting."""
        await self.exit_stack.aclose()

def clean_schema(schema):
    """
    Recursively removes 'title' and 'default' fields from the JSON schema.
    Also ensures that all properties of type OBJECT have at least one property.

    Args:
        schema (dict): The schema dictionary.

    Returns:
        dict: Cleaned schema without 'title' and 'default' fields and valid OBJECT types.
    """
    if not isinstance(schema, dict):
        return schema

    # Remove unnecessary fields
    schema.pop("title", None)
    schema.pop("default", None)

    # Handle OBJECT type with no properties
    if schema.get("type") == "object" and (not schema.get("properties") or len(schema.get("properties", {})) == 0):
        schema["properties"] = {
            "dummy": {
                "type": "string",
                "description": "Dummy parameter to satisfy API requirements"
            }
        }

    # Recursively clean nested properties
    if "properties" in schema and isinstance(schema["properties"], dict):
        for key, prop in schema["properties"].items():
            schema["properties"][key] = clean_schema(prop)

    return schema

def convert_mcp_tools_to_gemini(mcp_tools):
    """
    Converts MCP tool definitions to the correct format for Gemini API function calling.

    Args:
        mcp_tools (list): List of MCP tool objects with 'name', 'description', and 'inputSchema'.

    Returns:
        list: List of Gemini Tool objects with properly formatted function declarations.
    """
    gemini_tools = []

    for tool in mcp_tools:
        # Ensure inputSchema is a valid JSON schema and clean it
        parameters = clean_schema(tool.inputSchema)
        
        # Debug the schema before creating function declaration
        tool_name = tool.name
        print(f"Processing tool: {tool_name}")
        
        # Last check to ensure the schema is valid
        if parameters.get("type") == "object":
            if not parameters.get("properties"):
                parameters["properties"] = {
                    "dummy": {
                        "type": "string",
                        "description": "Dummy parameter to satisfy API requirements"
                    }
                }
            else:
                # Check for any nested object types with empty properties
                for prop_name, prop_schema in parameters["properties"].items():
                    if isinstance(prop_schema, dict) and prop_schema.get("type") == "object":
                        if not prop_schema.get("properties") or len(prop_schema.get("properties", {})) == 0:
                            # Add dummy property to nested object
                            parameters["properties"][prop_name]["properties"] = {
                                "dummy_nested": {
                                    "type": "string",
                                    "description": "Dummy nested parameter"
                                }
                            }

        # Construct the function declaration
        function_declaration = FunctionDeclaration(
            name=tool.name,
            description=tool.description,
            parameters=parameters  # Now correctly formatted
        )

        # Wrap in a Tool object
        gemini_tool = Tool(function_declarations=[function_declaration])
        gemini_tools.append(gemini_tool)

    return gemini_tools



async def main():
    """Main function to start the MCP client."""
    if len(sys.argv) < 2:
        print("Usage: python client.py <path_to_server_script>")
        sys.exit(1)

    client = MCPClient()
    try:
        # Connect to the MCP server and start the chat loop
        await client.connect_to_server(sys.argv[1])
        await client.chat_loop()
    finally:
        # Ensure resources are cleaned up
        await client.cleanup()

if __name__ == "__main__":
    # Run the main function within the asyncio event loop
    asyncio.run(main())

